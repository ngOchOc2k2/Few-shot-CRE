{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param trainable: 109482240\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from model.base_model import base_model\n",
    "import transformers\n",
    "from transformers import BertConfig, AutoTokenizer\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from model.base_model import AdapterModule\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from transformers import CLIPTextModel\n",
    "from peft import PeftConfig, PeftModel\n",
    "\n",
    "from transformers.activations import ACT2FN\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BaseModelOutputWithPoolingAndCrossAttentions,\n",
    ")\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "from transformers.utils import (\n",
    "    ModelOutput,\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    ")\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "# from peft import LoraConfig, TaskType\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType, PeftModel, PeftConfig # add\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from adapters import LoRAConfig, BertAdapterModel, PromptTuningConfig, IA3Config\n",
    "import adapters.composition as ac\n",
    "\n",
    "\n",
    "config_prompt = PromptTuningConfig(prompt_length=50)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = IA3Config()\n",
    "\n",
    "from adapters import ConfigUnion, PrefixTuningConfig, SeqBnConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=64, \n",
    "    lora_alpha=128, \n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.05, \n",
    "    # use_gating=True\n",
    ")\n",
    "\n",
    "config = PeftConfig.from_pretrained('/mnt/ngoclt/Continual Learning/SCKD_ori/SCKD/Checkpoint/LoRA')\n",
    "\n",
    "# model = get_peft_model(model, configs)\n",
    "\n",
    "# model = PeftModel.from_pretrained(model, configs, adapter_name=\"luungoc\")\n",
    "\n",
    "# model.load_adapter(configs, adapter_name=\"ngocluu\")\n",
    "\n",
    "# model.add_adapter(\"lora_adapter\", config=configs)\n",
    "\n",
    "# model.set_active_adapters(\"lora_adapter\")\n",
    "\n",
    "# model.train_adapter(\"lora_adapter\")\n",
    "\n",
    "print(f\"Param trainable: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "with open('/home/luungoc/Continual Learning/ConPL/data/tacred/CFRLdata_10_100_10_5/train_0.txt') as file_in:\n",
    "    for line in file_in:\n",
    "        items = line.strip().split('\\t')\n",
    "        if (len(items[0]) > 0):\n",
    "            relation_ix = int(items[0])\n",
    "            if items[1] != 'noNegativeAnswer':\n",
    "                candidate_ixs = [int(ix) for ix in items[1].split()]\n",
    "                sentence = items[2].split('\\n')[0]\n",
    "                headent = items[3]\n",
    "                headidx = [int(ix) for ix in items[4].split()]\n",
    "                tailent = items[5]\n",
    "                tailidx = [int(ix) for ix in items[6].split()]\n",
    "                headid = items[7]\n",
    "                tailid = items[8]\n",
    "                samples.append(\n",
    "                    [relation_ix, candidate_ixs, sentence, headent, headidx, tailent, tailidx,\n",
    "                        headid, tailid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "with open('/home/luungoc/Continual Learning/data/tacred/CFRLdata_10_100_10_5/train_0.txt') as file_in:\n",
    "    for line in file_in:\n",
    "        items = line.strip().split('\\t')\n",
    "        if (len(items[0]) > 0):\n",
    "            relation_ix = int(items[0])\n",
    "            if items[1] != 'noNegativeAnswer':\n",
    "                candidate_ixs = [int(ix) for ix in items[1].split()]\n",
    "                sentence = items[2].split('\\n')[0]\n",
    "                headent = items[3]\n",
    "                headidx = [int(ix) for ix in items[4].split()]\n",
    "                tailent = items[5]\n",
    "                tailidx = [int(ix) for ix in items[6].split()]\n",
    "                headid = items[7]\n",
    "                tailid = items[8]\n",
    "                samples.append(\n",
    "                    [relation_ix, candidate_ixs, sentence, headent, headidx, tailent, tailidx,\n",
    "                        headid, tailid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_index = np.load('/home/luungoc/Continual Learning/data/tacred/rel_index.npy')\n",
    "rel_cluster_label = np.load('/home/luungoc/Continual Learning/data/tacred/CFRLdata_10_100_10_10/rel_cluster_label_0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation Index: [ 1  2  3 26  5 29  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25  4 27 28  6 30 31 32 33 34 35 36 37 38 39 40 41]\n",
      "Relation Cluster Label: [4 1 6 3 2 4 7 1 3 4 3 1 6 0 0 6 5 2 0 7 0 5 4 5 7 1 7 2 5 7 0 6 7 2 3 2 3\n",
      " 1 6 5 4]\n"
     ]
    }
   ],
   "source": [
    "print(f'Relation Index: {rel_index}')\n",
    "\n",
    "print(f'Relation Cluster Label: {rel_cluster_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_labels = {}\n",
    "for index, i in enumerate(rel_index):\n",
    "    if rel_cluster_label[index] in cluster_to_labels.keys():\n",
    "        cluster_to_labels[rel_cluster_label[index]].append(i-1)\n",
    "    else:\n",
    "        cluster_to_labels[rel_cluster_label[index]] = [i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: [0, 28, 9, 22, 40],\n",
       " 1: [1, 7, 11, 3, 37],\n",
       " 6: [2, 12, 15, 31, 38],\n",
       " 3: [25, 8, 10, 34, 36],\n",
       " 2: [4, 17, 27, 33, 35],\n",
       " 7: [6, 19, 24, 26, 29, 32],\n",
       " 0: [13, 14, 18, 20, 30],\n",
       " 5: [16, 21, 23, 5, 39]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_to_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ngoclt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
